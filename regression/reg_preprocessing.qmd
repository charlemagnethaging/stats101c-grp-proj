---
title: 'Regression Data Preprocessing'
format:
  html:
    toc: true
    code-fold: true
    embed-resources: true
    fig-align: center

---

```{r}
#| label: setup
#| include: false
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(rpart)
library(mlr3verse)
library(ggplot2)
library(xgboost)
library(dplyr)
library(rpart)
library(broom)
library(glmnet)
library(stringr)
library(janitor)
```


```{r}
#| label: read data, format var names

# Load datasets
purchases <- read_csv("data/amazon-purchases.csv")
survey <- read_csv("data/survey_train_test.csv")

purchases <- purchases |> clean_names(sep_out = ".")
survey <- survey |> clean_names(sep_out = ".")
```

```{r cat-umbrella-regex}
#| label: category umbrella

## Umbrella grouping for categories (second attempt)

# regex keywords -> umbrella

# 1. Baby & Kids
pat_baby <- "BABY|INFANT|DIAPER|NURSERY|STROLLER|CRIB|PACIFIER|WIPE|CAR_SEAT|HIGH_CHAIR|SAFETY_GATE|BREAST_PUMP|KIDS_ROOM|TEETHER|NOISE_MACHINE|TRAMPOLINE|COLLAPSIBLE_PLAY_STRUCTURE|CHANGING_PAD"

# 2. Video Games
pat_video_games <- "VIDEO_GAME|CONSOLE|CONTROLLER|NINTENDO|XBOX|PLAYSTATION|GAMING|GAME_BOY|DIGITAL_GAME|VIRTUAL_REALITY_HEADSET"

# 3. Electronics (Added: TELEVISION, ANTENNA, RADIO, RECEIVER, CALCULATOR)
pat_electronics <- "COMPUTER|LAPTOP|TABLET|PHONE|MOBILE|WIRELESS|HEADPHONE|SPEAKER|CAMERA|AUDIO|VIDEO|TV|TELEVISION|MONITOR|SCREEN|PROTECT|CABLE|CHARGER|ADAPTER|POWER|BATTERY|MOUSE|KEYBOARD|DRIVE|MEMORY|USB|PRINTER|DEVICE|CASE|COVER|FLASH|STRIP|DIGITAL|REMOTE|SWITCH|FILAMENT|COMPONENT|HUB|MULTIPORT|CAMCORDER|FILM|MOUNT|ELECTRONIC|ROUTER|NETWORK|SOFTWARE|ANTENNA|RADIO|RECEIVER|CALCULATOR|ALARM|MODEM"

# 4. Grocery & Food (Added: PIZZA, HONEY, PICKLE)
pat_grocery <- "FOOD|GROCERY|SNACK|CANDY|CHOCOLATE|BEVERAGE|COFFEE|TEA|JUICE|WATER|MEAT|DAIRY|SPICE|SAUCE|PANTRY|CEREAL|OIL|VINEGAR|COOK|DRINK|FRUIT|BREAD|POULTRY|HERB|NOODLE|SOUP|CRACKER|STEW|FLAVOR|NUT|SEED|LEGUME|JERKY|SYRUP|GUM|BUTTER|MILK|BAKE|BAKING|FLOUR|POPCORN|CONDIMENT|SUGAR|SEASON|CAKE|PASTRY|MEAL|EGG|PRETZEL|THICKEN|LEAVEN|CULINARY|VEGETABLE|PIZZA|HONEY|PICKLE|BEER|WINE|CASSEROLE"

# 5. Apparel (Added: SCARF, SLEEPWEAR, NECKTIE, BADGE, SWEATBAND, APRON)
pat_apparel <- "CLOTH|SHIRT|PANT|DRESS|COAT|JACKET|SWEATER|UNDERWEAR|SOCK|SHOE|BOOT|SNEAKER|BAG|HANDBAG|WALLET|WATCH|JEWELRY|ACCESSOR|SUNGLASSES|HAT|CAP|APPAREL|BRA|SWIM|SHORT|SANDAL|SLIPPER|PAJAMA|NECKLACE|RING|EARRING|GLOVE|SKIRT|LEOTARD|TUNIC|TIGHT|WIG|KEYCHAIN|OUTFIT|WAIST|GLASSES|STRAP|COSTUME|ROBE|CHARM|SCARF|SLEEPWEAR|NECKTIE|BADGE|SWEATBAND|APRON|EARMUFF|SUIT|CORSET|VEST|BLAZER|OVERALLS|FASHIONOTHER"

# 6. Health & Medical
pat_health <- "HEALTH|MEDIC|VITAMIN|SUPPLEMENT|FIRST_AID|BRACE|THERMOMETER|MASK|OPTICAL|LENS|DRUG|INCONTINENCE|SCALE|WEIGH|RESPIRATOR|SANITARY|BODY_POS|LAB_SUPPLY|EARPLUG|WALKER|WHEELCHAIR|CANE|THERAPEUTIC|COMPRESS|TAMPON|CONDOM|SANITIZER|WALKING_STICK|GLUCOSE_METER"

# 7. Beauty & Personal Care (Added: TANNER, TWEEZER, DYE, TATTOO, SCRAPER)
pat_beauty <- "MAKE_UP|BEAUTY|MAKEUP|SKIN|HAIR|COSMETIC|PERFUME|FRAGRAN|SHAMPOO|LOTION|NAIL|SHAV|RAZOR|GROOM|TOOTH|DENTAL|SALON|HYGIENE|DEODORANT|CONDITION|BALM|SUNSCREEN|MASSAG|LIP|MASCARA|EYELID|MOUTHWASH|LUBRICANT|LINT|EYELASH|EYEBROW|COTTON|SPONGE|TANNER|TWEEZER|DYE|TATTOO|SCRAPER|ORAL|CARE|AXE"

# 8. Household Essentials
pat_household <- "PAPER_TOWEL|TOILET_PAPER|CLEAN|DETERGENT|TRASH|LAUNDRY|SOAP|TISSUE|FOIL|WRAP|AIR_FRESH|DISINFECT|PEST|ADHESIVE|TAPE|BONDING|DEODORIZ|SOFTENER|VACUUM|MOP|BROOM|BUCKET|PURIFIER|HUMIDIFIER|DIFFUSER|INCENSE|TRAP|SQUEEGEE|BLEACH"

# 9. Home Decor & Furniture (Added: BASKET, HEATER, SCULPTURE, HANGER, TIMER)
pat_home <- "SHADE|FURNITURE|BED|MATTRESS|RUG|CURTAIN|DECOR|FRAME|SHEET|PILLOW|STORAGE|MIRROR|SOFA|CHAIR|DESK|TABLE|CABINET|SHELF|HOME|CLOSET|BLANKET|TOWEL|CADDY|FIGURINE|STICKER|ART|BANNER|ORNAMENT|FAN|ROD|THERMOS|WALL|MAT|CLOCK|VASE|SHOWER|SIGNAGE|ALBUM|BASKET|HEATER|SCULPTURE|HANGER|TIMER|SAFE|OTTOMAN"

# 10. Kitchen & Dining (Added: FLATWARE, SPOON, PITCHER, NAPKIN)
pat_kitchen <- "CHOPSTICK|KITCHEN|COOK|BAKE|DISH|KNIFE|PAN|POT|BLENDER|MIXER|TOASTER|MICROWAVE|REFRIGERATOR|CUTLERY|SPATULA|BOWL|CUP|MUG|DINING|GLASSWARE|BOTTLE|THERMOS|TRAY|CONTAINER|LID|ICE|COUNTERTOP|DRYING_RACK|AIR_FRYER|GRILL|OVEN|UTENSIL|FLASK|FLATWARE|SPOON|PITCHER|NAPKIN|JAR|FORK|TRIVET"

# 11. Pets (Added: VIVARIUM)
pat_pets <- "PET|DOG|CAT|ANIMAL|FISH|AQUARIUM|LITTER|HAMSTER|BIRD|REPTILE|VETERINARY|LEASH|FEEDER|VIVARIUM"

# 12. Sports & Outdoors
pat_sports <- "SPORT|EXERCISE|GYM|FITNESS|CAMPING|HIKING|TENT|FISHING|BIKE|BICYCLE|GOLF|BALL|HELMET|BACKPACK|SLEEPING_BAG|HAMMOCK|KNEE_PAD|MUSCLE|OUTERWEAR|STRENGTH|\\w+BELL|TREADMILL|SLEEVE|CARABINER|JUMP_ROPE|PULL_UP_BAR"

# 13. Garden & Outdoor Living (Added: UMBRELLA)
pat_garden <- "GARDEN|LAWN|PLANT|PATIO|POOL|FERTILIZER|WEED|MOSS|INSECT|REPELLENT|HOSE|SPRINKLER|SEED|SNOW|UMBRELLA|SPADE|TARP|LEAF_BLOWER"

# 14. DIY, Auto & Tools (Added: FAUCET, DRAIN, SEALANT, ANCHOR)
pat_diy_auto <- "LIGHT|TOOL|HARDWARE|DRILL|SAW|HAMMER|SCREW|WRENCH|PLUMBING|FIXTURE|PAINT|LADDER|LOCK|SANDPAPER|AUTO|VEHICLE|CAR_|TIRE|OIL|MOTOR|WIPER|BRAKE|LIGHTING|LAMP|BULB|FLASHLIGHT|HVAC|FILTER|BUILDING|VALVE|PIPE|PUMP|FIRE|LIGHTER|COMPRESSOR|GENERATOR|UTILITY|KIT|FAUCET|DRAIN|SEALANT|ANCHOR|PLUG|ELECTR|MECHANICAL|DOOR|CORD|WIRE|CAULK|INDUSTRIAL|TILE|MACHINE|SAND|GLUE|BOLT|PLIERS|GASKET|BLOWTORCH|CARBURETOR|FUSE|HOLE_PUNCH|WASHER|RELAY|INSULATION|WHEEL"

# 15. Office & School (Added: NOTE, ERASER, STAMP)
pat_office <- "OFFICE|PAPER|PEN|PENCIL|NOTEBOOK|BINDER|STAPLER|ENVELOPE|LABEL|DESK_ACCESSORY|FILE|FOLDER|SCISSOR|STATIONERY|WRITING|PLANNER|CALENDAR|BOARD|CARD|NOTE|ERASER|STAMP|RULER"

# 16. Arts & Crafts (Added: THREAD)
pat_arts <- "ART|CRAFT|SEWING|KNITTING|YARN|FABRIC|BEAD|CANVAS|PAINT_BRUSH|EASEL|SCRAPBOOK|THREAD"

# 17. Toys & Hobbies
pat_toys <- "TOY|PUZZLE|DOLL|FIGURE|LEGO|HOBBY|COLLECTIBLE|MODEL|DRONE|ROBOT|PLAYSET|FIDGE|PRETEND|STUFFED_ANIMAL|EQUIPMENT|PLECTRUM|BINOCULAR|GAME|GUITAR|SCOOTER|SKATE|BACKDROP|HOBBIE|TELESCOPE"

# 18. Books & Media
pat_media <- "BOOK|DVD|MOVIE|MUSIC|CD|VINYL|MAGAZINE|MEDIA"

# 19. Party & Occasion
pat_party <- "PARTY|GIFT|WRAP|DECORATION|BALLOON|FAVOR|CANDLE|RIBBON|BOW|CONFETTI"

# Note: The order here implies priority in the case_when below i.e. if a keyphrase is in multiple patterns, it will be sorted into the first one below
category_lookup <- purchases |>
	distinct(category) |> # speed up process by shrinking dataset to unique categories = nrows
	mutate(
		umbrella_category = case_when(
			# 0. Missing Data
			is.na(category) ~ "Unknown",
			# 1. High Priority / Specific
			str_detect(category, regex(pat_baby, ignore_case = TRUE)) ~ "Baby_Product",
			str_detect(category, regex(pat_video_games, ignore_case = TRUE)) ~ "Video_Games",
			str_detect(category, regex(pat_electronics, ignore_case = TRUE)) ~ "Electronics_and_Computers",
			# 2. Food & Consumables
			str_detect(category, regex(pat_grocery, ignore_case = TRUE)) ~ "Grocery_and_Food",
			# 3. Personal Items
			str_detect(category, regex(pat_apparel, ignore_case = TRUE)) ~ "Apparel_and_Accessories",
			str_detect(category, regex(pat_health, ignore_case = TRUE)) ~ "Health_and_Medical",
			str_detect(category, regex(pat_beauty, ignore_case = TRUE)) ~ "Beauty_and_Personal_Care",
			# 4. Home & Living (Order matters: Essentials -> Kitchen -> Decor -> General)
			str_detect(category, regex(pat_household, ignore_case = TRUE)) ~ "Household_Essentials",
			str_detect(category, regex(pat_kitchen, ignore_case = TRUE)) ~ "Kitchen_and_Dining",
			str_detect(category, regex(pat_home, ignore_case = TRUE)) ~ "Home_Decor_and_Furniture",
			# 5. Specialized
			str_detect(category, regex(pat_pets, ignore_case = TRUE)) ~ "Pet_Supplies",
			str_detect(category, regex(pat_sports, ignore_case = TRUE)) ~ "Sports_and_Outdoors",
			str_detect(category, regex(pat_garden, ignore_case = TRUE)) ~ "Garden_and_Outdoor",
			str_detect(category, regex(pat_diy_auto, ignore_case = TRUE)) ~ "DIY_Auto_and_Lighting",
			str_detect(category, regex(pat_arts, ignore_case = TRUE)) ~ "Arts_and_Crafts",
      str_detect(category, regex(pat_toys, ignore_case = TRUE)) ~ "Toys_and_Hobbies",
			# 6. General / Low Priority
			str_detect(category, regex(pat_office, ignore_case = TRUE)) ~ "Office_and_School",
			str_detect(category, regex(pat_media, ignore_case = TRUE)) ~ "Books_and_Media",
			str_detect(category, regex(pat_party, ignore_case = TRUE)) ~ "Party_and_Occasion",

			TRUE ~ "Other"))

# join category -> umbrella category maps back to purchases

purchases <- purchases |>
	left_join(category_lookup, by = "category")

# check umbrella sizes

purchases |>
	select(umbrella_category) |>
	count(umbrella_category, sort = TRUE) |> 
  print(n=30)

# check leftover "Other" categories

purchases |>
	filter(umbrella_category == "Other") |>
	count(category, sort = TRUE) |> filter(n>=100) |> print(n=100)
```

This is Charlie's revised category summation. I did use Gemini to help initally sort categories into umbrellas, and supervised its sorting and then did manual sorting (by investigating leftover Other column multiple times and updating the umbrella regex patterns with new keywords) to reduce the "Other" category further.


```{r}
#| label: drop unused purchases cols

purchases <- purchases |> select(!c(title, asin.isbn.product.code, category)) |> 
  relocate(survey.response.id)
```

```{r}
#| label: flatten purchases data

## create category freq per id
# n.distinct.categories

cat_freq_by_id <- purchases |>
	group_by(survey.response.id) |>
	mutate(total_user_purchases = n()) |> # total purchases made per-user
	group_by(survey.response.id, umbrella_category, total_user_purchases) |>
	summarise(n = n(), .groups = "drop") |> # purchases per-user, per-category
	mutate(share = n / total_user_purchases) |> # category share per-user
	pivot_wider(
		id_cols = "survey.response.id",
		names_from = "umbrella_category",
		values_from = "share",
		names_prefix = "freq_",
		values_fill = 0 # default behavior would fill unpurchased-from categories with NA
	) |> rowwise() |> 
    mutate(n.distinct.categories = sum(c_across(starts_with("freq_")) > 0), .after="survey.response.id")

## top shipping address state for each ID

top_destination_state_by_id <- purchases |>
	group_by(survey.response.id, shipping.address.state) |>
	summarise(n = n(), .groups = 'drop_last') |>
	arrange(desc(n), .by_group = TRUE) |>
	mutate(shipping.address.state = replace_na(shipping.address.state, replace = "digital/locker")) |>
	# some users' top state is NA ("Shipping Address State is often missing when the purchased item is a digital good, such as a digital gift card, or when the order was delivered to an Amazon locker." - from data source)
	slice_head(n = 1) |>
	select(survey.response.id, shipping.address.state) |>
	ungroup()


## summarize spending data

# summarize total.spent by the user
# and the average amount spent per order for the user
# and total.order.count
purchases <- purchases |>
	group_by(survey.response.id, order.date) |>
	summarize(order.price = sum(purchase.price.per.unit * quantity),
            n.orders=n()) |> # sum prices & orders in a day per-user
	group_by(survey.response.id) |>
	summarize(
    total.spent = sum(order.price), 
    total.orders = sum(n.orders),
    avg.order.price = mean(order.price), 
    .groups='drop')

## add cols for total spend per category?

## merge category and address data into spending

purchases <- purchases |>
  left_join(top_destination_state_by_id, by = "survey.response.id") |> 
	left_join(cat_freq_by_id, by = "survey.response.id") 
```


```{r clean survey data + join}
#| label: join survey data + save

## drop cols unused cols from survey data (not avail at sign-up)
survey <- survey |> select(survey.response.id, q.demos.gender, q.demos.state, q.amazon.use.hh.size.num)

# Full join datasets on Survey Response ID
data <- full_join(purchases, survey, by = join_by(survey.response.id))

# set character vars as factor
data <- data |>
  mutate(
    across(where(is.character), as.factor),
    survey.response.id = as.character(survey.response.id) # keep id as simple string
  ) |> 
  relocate(where(is.factor), .after="survey.response.id") # move factor vars to the left

train_data <- data |> drop_na(q.amazon.use.hh.size.num)
test_data <- data |> filter(is.na(q.amazon.use.hh.size.num))

save(train_data, file = "processed_data_train.RData")
save(test_data, file = "processed_data_test.RData")
```

