---
title: "Stats 101C Regression Final"
author: "Group 13"
date: "`r Sys.Date()`"
output:
  pdf:
    toc: true
    toc_depth: 3
  html:
    toc: true
    toc_depth: 3
embed-resources: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.width=7, fig.height=5)
library(tidyverse)
library(rpart)
library(mlr3verse)
library(xgboost)
library(broom)
library(glmnet)
```

```{r}
# Load data
load("processed_data_train.RData")
```

# Introduction 

Research shows that factors such as income, age, gender, and household composition often influence spending behavior and product choice (U.S. Bureau of Labor Statistics). This background makes us interested to see if online spending is associated with variables such as income, education, age, and household sizes. The household size could be associated with how often and how many products are typically purchased but the different demographics of the customer or household could be associated with the purchase category. Personal habits and factors related to personal health could also place an influential role in purchasing behavior. These variables are all plausible predictors of online spending behavior.

## Exploratory Data Analysis
As we explored potential relationships between the variables in the training dataset, notable patterns were discovered and some failed to show. Our findings are presented below: 

### Response (HH Size) Distribution

```{r, fig.width=10, fig.height=6}
set_theme(theme_minimal())

ggplot(data, aes(x = q.amazon.use.hh.size.num, fill=q.amazon.use.hh.size.num, group=as.factor(q.amazon.use.hh.size.num))) +
  geom_bar() +
  scale_fill_gradient(low="#ccebc5", high="#08589e") +
  labs(title = "Distribution of Housing Size",
       x = "Housing Size",
       y = "Count"
       ) +
  theme(legend.position="none")
```

Just looking at the distribution of housing sizes, we see that it's most common for households to have a size of 2, with size 4+ or 1 the second most frequent, and a size of 3 having the lowest frequency. Since household sizes of 4 and more are represented by only one variable, it's difficult to tell what the breakdown of household sizes are within that variable. 

### Numeric Variable Correlation

```{r, fig.width=10, fig.height=6}
numeric_data <- data |> 
  select(where(is.numeric))

# Compute correlation matrix
cor_matrix <- cor(numeric_data, use = "pairwise.complete.obs")

# Convert to long format for ggplot
cor_long <- as.data.frame(as.table(cor_matrix))

ggplot(cor_long, aes(Var1, Var2, fill = Freq)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "darkgreen", high = "pink", mid = "white",
                       midpoint = 0, limit = c(-1,1), space = "Lab",
                       name = "Correlation") +
  geom_text(aes(label = round(Freq, 2)), color = "black", size = 4) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(title = "Correlation Matrix Heatmap (Numeric Variables)", x = "", y = "")
```

From our correlation heat map, we notice that all the numerical variables do not show any kind of correlation among each other. Surprisingly the amount of products purchased and the number of users per amazon account doesn't have any correlation to the household size. The variable interactions seem to be statistically negligible in terms of a linear relationship. 


### Location

```{r, fig.width=10, fig.height=6}
ggplot(data, aes(y = fct_rev(fct_infreq(shipping.address.state)))) +
	geom_bar(fill = "#7ec17bff") +
	labs(
		title = "Distribution of Shipping Address",
		y = "Shipping Address State"
	)

# top_25_states <- data |>
# 	count(shipping.address.state) |>
# 	slice_max(n, n = 25) |>
# 	pull(shipping.address.state)

# # plot distr hhsize for top 25 states
# data |>
# 	filter(shipping.address.state %in% top_25_states) |>
# 	ggplot(aes(y = fct_rev(fct_infreq(shipping.address.state)), x = q.amazon.use.hh.size.num)) +
# 	geom_violin() +
# 	labs(title = "Average Housing Size by State", y = "State", x = "Mean Housing Size")

# diff attempt at plotting per-state distr of hhsize
state_order <- data %>%
  group_by(shipping.address.state) %>%
  summarize(prop_size_1 = mean(q.amazon.use.hh.size.num == 1)) %>% 
  arrange(desc(prop_size_1)) %>%  # Use desc(prop_size_2) if you want top-to-bottom
  pull(shipping.address.state)

data |> mutate(shipping.address.state = factor(shipping.address.state, levels = state_order)) |> 
  ggplot(aes(
		x = shipping.address.state,
		fill = q.amazon.use.hh.size.num,
		group = as.factor(q.amazon.use.hh.size.num)
)) +
	geom_bar(position = position_fill(reverse = TRUE)) +
	scale_fill_gradient(low="#ccebc5", high="#08589e") +
	coord_flip() +
	labs(y = "Proportion", x = "Shipping Address", fill = "HH Size")
```

Interested in seeing if the state/location would show any noticeable patterns in the housing size, our visual showed that the state doesn't seem to make a difference on the average housing size. This suggests that more populated states might not be very important to consider in our final model. Most states tend to average around 2 to 3 for their household size. Hawaii surprisingly shows the highest average while Puerto Rico shows the smallest, yet they are both very small territories.  

### Product Categories

```{r}
# plot correlated cat frequencies against hhsize

ggplot(
  data |> filter(freq_Toys_and_Hobbies > 0), 
  aes(x = q.amazon.use.hh.size.num, y = freq_Toys_and_Hobbies)) +
	geom_jitter(alpha = 0.5)

ggplot(data |> filter(freq_Baby_Product > 0), 
aes(x = q.amazon.use.hh.size.num, y = freq_Baby_Product)) +
	geom_jitter(alpha = 0.5)
```

Certain households would be more likely to purchase products from specific product categories like households with children would be like to purchase products related to toys. Looking at the top 10 purchased product categories, household sizes closer to 3 purchase from these categories, but we noticed that the pet food category showed a household size closer to 2. This makes us believe that there could be certain categories that may be able to predict smaller household sizes better than others. 

### Demographics

#### isHispanic

```{r}
ggplot(data, aes(x = q.demos.hispanic, y = q.amazon.use.hh.size.num, fill = q.demos.hispanic)) +
  geom_violin() +
  labs(title = "Housing Size vs. Is Hispanic ",
       x = "Is Hispanic? (Yes or No)",
       y = "Housing Size") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Interestingly, we noticed that if a household has a non-Hispanic origin, it's more common for the household size to 2 than any other size. This variable is worth investigating further. 

#### Race

```{r}
ggplot(data, aes(x = q.demos.race, y = q.amazon.use.hh.size.num)) +
  geom_boxplot() +
  facet_wrap(~ q.demos.race, scales = "free_x", nrow = 6) +
  labs(title = "Housing Size vs. Race",
       x = "Race",
       y = "Housing Size") +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
```

After seeing the distribution of household sizes when a household is Hispanic or not, we were interested to see if race would should any patterns and it definitely did. The distributions in household sizes by different races showed many different results which made it evident that race could be a strong predictor for our model. 

#### Gender

```{r}
ggplot(data, aes(x = q.demos.gender, y = q.amazon.use.hh.size.num)) +
  geom_violin() +
  labs(title = "Housing Size vs. Gender ",
       x = "Gender",
       y = "Housing Size") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

The demographic-related variables we've explored have shown to be useful predictors so we wanted to see if gender would show any patterns as well. However, the violin plots for "Female" and "Male" show their widest density at exactly the same points: at 2 and 3. The most common household sizes are identical for the two largest gender groups and the violin plots fail to show that one gender group's distribution is systematically larger or smaller than another's. Including gender in our model would likely add very little explanatory power. 

#### Gender:Income

```{r}
ggplot(data, aes(x = q.demos.gender, y = q.amazon.use.hh.size.num, fill = q.demos.income)) +
  geom_boxplot() +
  labs(title = "Housing Size vs. Gender ",
       x = "Gender",
       y = "Housing Size") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We wanted to see if the interaction effect between gender and income would show anything different, and we were able to identify patterns of variation in household size. This told use that distribution of housing size is strongly affected by income regardless of gender and the predictive power of income is strong. 

#### Sexual Orientation

```{r}
ggplot(data, aes(x = q.sexual.orientation, y = q.amazon.use.hh.size.num)) +
  geom_violin() +
  labs(title = "Housing Size vs. Sexual Orientation ",
       x = "Sexual Orientation",
       y = "Housing Size") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Although gender did not show to have strong predictive power, sexual orientation may be a modest predictor. There is difference in the proportions of individuals at size 2 and 3 for the heterosexual and LGBTQ+ category, but this still tells us that the typical household size structure is very similar for these two groups so we would consider sexual orientation a weak predictor. There's also no clear shift where one entire distribution is significantly higher or lower than the others. 

#### Education

```{r}
ggplot(data, aes(x = q.demos.education, y = q.amazon.use.hh.size.num)) +
  geom_violin() +
  labs(title = "Housing Size vs. Education Level ",
       x = "Completed Education Level",
       y = "Housing Size") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
The violin plot shows that the underlying distribution of raw data is nearly identical for most education levels. This lack of separation in the raw data distribution means that knowing someone's education level doesn't tell you much more about their typical household size. 

#### Shared Account

```{r}
ggplot(data, aes(x = q.amazon.use.howmany, y = q.amazon.use.hh.size.num)) +
  geom_boxplot() +
  labs(title = "Housing Size vs. Users per Account ",
       x = "Users per Account",
       y = "Housing Size") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We see an upward trend of in the distribution of housing size as the number of users per account increases. Although accounts with 2 or more users have the same distribution. The shift in the central tendency of household size shows the ability to separate the data into two distinct groups with different medians and distributions. This makes us believe that a binary indicator of if the account is shared or not could be a potentially useful predictor. 

### Order Frequency

```{r}
ggplot(data, aes(x = q.amazon.use.how.oft, y = q.amazon.use.hh.size.num)) +
  geom_boxplot() +
  labs(title = "Housing Size vs. Order Frequency ",
       x = "Order Frequency",
       y = "Housing Size") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
The number of deliveries made per account appears to be a poor predictor of household size. We see different trend of in the distribution of housing size as the number of orders per month increases, however, accounts that deliver up to 10 times a month have the same median which make us hesitant about the usefulness of the variable since it may have poor predictive power for the majority of the data. There is still a median shift as order frequencies increase past 10 but the distribution for this group has a large overlap with the others.  

### Health info

```{r}
life_data <- data %>%
  select(q.personal.diabetes,
         q.personal.wheelchair,
         q.amazon.use.hh.size.num) %>%
  pivot_longer(
    cols = c("q.personal.diabetes", "q.personal.wheelchair"),
    names_to = "Behavior",
    values_to = "Response"
  )

ggplot(life_data, aes(x = Response, y = q.amazon.use.hh.size.num, fill = Response)) +
  geom_boxplot() +
  facet_wrap(~Behavior, scales = "free_x") +
  labs(
    title = "Housing Size Across Personal Factors",
    x = "Response",
    y = "Housing Size"
  ) +
  theme_minimal()
```

Both factors possess modest predictive power because they successfully create categorical groups where the typical median household size is different (2 vs. 3). However, they are not strong predictors because their IQRs still heavily overlap, meaning the distributions are not completely separated. 

### Life Changes

```{r}
# Top 10 Life Changes
top_life_changes <- data %>%
  count(q.life.changes) %>%
  arrange(desc(n)) %>%
  dplyr::slice(1:10) %>%      
  pull(q.life.changes)

life_changes_data <- data %>%
  filter(q.life.changes %in% top_life_changes)

summary_df <- life_changes_data %>%
  group_by(q.life.changes) %>%
  summarize(
    mean_size = mean(q.amazon.use.hh.size.num, na.rm = TRUE),
    se = sd(q.amazon.use.hh.size.num, na.rm = TRUE) / sqrt(n())
  )

ggplot(summary_df, aes(x = reorder(q.life.changes, mean_size), y = mean_size)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_size - 1.96*se,
                    ymax = mean_size + 1.96*se),
                width = 0.2) +
  coord_flip() +
  labs(
    title = "Mean Housing Size by Most Common Life Changes",
    x = "Life Change",
    y = "Mean Housing Size"
  )
```

The life.changes variable would be useful for prediction, as several categories show a clear stratification of the means. Our model can leverage the fact that people who moved or lost a job tend to have smaller average household sizes than those who had a child or got divorced.

### Order Date

```{r}
date_data <- data %>%
  mutate(
    Order.Date = as.Date(Order.Date),         
    Year = format(Order.Date, "%Y"),
    Month = format(Order.Date, "%m")
  )

date_data %>%
  group_by(Year, Month) %>%
  summarise(mean_housing = mean(q.amazon.use.hh.size.num, na.rm = TRUE)) %>%
  ggplot(aes(x = Month, y = mean_housing, color = Year, group = Year)) +
  geom_line(size = 1) +
  geom_point() +
  labs(
    title = "Monthly Trends in Housing Size by Year",
    x = "Month",
    y = "Average Housing Size"
  ) +
  theme_minimal()
```

After analyzing the average housing size by month and year, the order date variable does not appear to make a significant difference in the average household size. The average housing size across all years remains extremely stable throughout the months and there are no major seasonal spikes or drops where the average housing size changes significantly.


## Preprocessing
```{r}
## Drop unnecessary columns 
cols_to_drop <- c("Survey.ResponseID", "Order.Date", "shipping.address.state","Title",
                  "ASIN.ISBN..Product.Code.", "q.demos.education", "q.demos.gender", 
                  "q.sexual.orientation", "q.demos.state", "q.amazon.use.hh.size", 
                  "q.amazon.use.how.oft", "q.substance.use.cigarettes", 
                  "q.substance.use.marijuana", "q.substance.use.alcohol", 
                  "q.personal.diabetes",  "q.personal.wheelchair", 
                  "q.sell.YOUR.data", "q.sell.consumer.data", "q.small.biz.use", 
                  "q.census.use", "q.research.society", "test")
data <- data %>% select(setdiff(colnames(data), cols_to_drop))

## Create an encoded binary variable for shared accounts
data <- data %>%
  mutate(
    sharedAccount = case_when(
      # keep NA as NA
      is.na(q.amazon.use.howmany) ~ NA, 
      
      # anything starting with 1 is FALSE
      grepl("^1", q.amazon.use.howmany) ~ 0, 
      
      # all other values are TRUE
      TRUE ~ 1 
    )
  )

# Drop rows where the category column is an empty string ("")
data <- subset(data, category != "")

## Keep only rows where category is in the top 500 most frequent categories
freq <- sort(table(data$category), decreasing = TRUE)
top_categories <- names(freq)[1:500]
data <- subset(data, category %in% top_categories)

## Umbrella groups for the category variable
data <- data %>%
  mutate(category = case_when(
    str_detect(category, 
               regex("BOOK|MUSIC|DVD", ignore_case = TRUE)) ~ "Media",
    str_detect(category, 
               regex("TOY|GAME|FIGURE|PUZZLE", ignore_case = TRUE)) ~ "Games",
    str_detect(category, 
               regex("SHIRT|PANTS|DRESS|SHORTS|SWIMWEAR|SWEATER|SWEATSHIRT|BRA|UNDERPANTS|PAJAMAS|TUNIC|LEOTARD|ONE_PIECE_OUTFIT|APPAREL", ignore_case = TRUE)) ~ "Clothing",
    str_detect(category, 
               regex("PET|ANIMAL", ignore_case = TRUE)) ~ "Pet",
    str_detect(category, 
               regex("FOOD|SNACK|COFFEE|TEA|JUICE|MILK|BREAD|CHOCOLATE|SAUCE|SUGAR|NOODLE|RICE|PASTRY", ignore_case = TRUE)) ~ "Food",
    str_detect(category, 
               regex("BEAUTY|SKIN|HAIR|COSMETIC|FRAGRANCE|LIP|MASCARA|NAIL", ignore_case = TRUE)) ~ "Beauty",
    str_detect(category, 
               regex("ELECTRONIC|PHONE|HEADPHONES|CAMERA|MONITOR|FLASH|COMPUTER|TABLET|ACCESSORY|INPUT|DEVICE|DRIVE", ignore_case = TRUE)) ~ "Electronics",
    str_detect(category, 
               regex("HOME|FURNITURE|LAMP|LIVING|DECOR|BED|BATH|KITCHEN|STORAGE|CLEANING|APPLIANCE|TOOL|LIGHT", ignore_case = TRUE)) ~ "Home",
    str_detect(category, 
               regex("SPORT|EXERCISE|FITNESS|RECREATION", ignore_case = TRUE)) ~ "Fitness",
    str_detect(category, 
               regex("HEALTH|MEDICATION|SUPPLEMENT|VITAMIN|THERMOMETER|ORTHOPEDIC|PROTECTOR", ignore_case = TRUE)) ~ "Health",
    str_detect(category, 
               regex("STATIONERY|PAPER|MARKING|INK|PEN|WRITING|NOTEBOOK", ignore_case = TRUE)) ~ "Stationery",
    TRUE ~ "Other"
  ))

## Hot encoding for the multiple choice Life Changes variable 
data <- data %>%
  mutate(
    # create multi-hot encoded columns
    change_employment  = ifelse(str_detect(q.life.changes, regex("Lost a job", ignore_case = TRUE)), 1, 0),
    change_relocation  = ifelse(str_detect(q.life.changes, regex("Moved place of residence", ignore_case = TRUE)), 1, 0),
    change_relationship = ifelse(str_detect(q.life.changes, regex("Divorce", ignore_case = TRUE)), 1, 0),
    change_family      = ifelse(str_detect(q.life.changes, regex("Became pregnant|Had a child", ignore_case = TRUE)), 1, 0),
    # No categories selected
    change_none = ifelse(q.life.changes == "", 1, 0)
  )

## 
data <- data %>%
  mutate(
    race_white = ifelse(str_detect(q.demos.race, regex("White|Caucasian", ignore_case = TRUE)), 1, 0),
    race_black = ifelse(str_detect(q.demos.race, regex("Black|African American", ignore_case = TRUE)), 1, 0),
    race_asian = ifelse(str_detect(q.demos.race, 
                                   regex("Asian", ignore_case = TRUE)), 1, 0),
    race_native_american = ifelse(str_detect(q.demos.race, 
                                   regex("American Indian|Native American|Alaska Native", ignore_case = TRUE)), 1, 0),
    race_pacific_islander = ifelse(str_detect(q.demos.race, 
                                   regex("Native Hawaiian|Pacific Islander",
                                         ignore_case = TRUE)), 1, 0),
    race_other = ifelse(str_detect(q.demos.race, 
                                   regex("Other", ignore_case = TRUE)), 1, 0)
  )

## Drop the columns we encoded
data <- data %>% select(setdiff(colnames(data), c("q.amazon.use.howmany", "q.life.changes", "q.demos.race")))


## Converting categorical variables to their numeric midpoints
data <- data %>%
  mutate(
    # Household income: numeric midpoints
    q.demos.income = case_when(
      q.demos.income == "Less than $25,000"       ~ 12500,
      q.demos.income == "$25,000 - $49,999"       ~ 37500,
      q.demos.income == "$50,000 - $74,999"       ~ 62500,
      q.demos.income == "$75,000 - $99,999"       ~ 87500,
      q.demos.income == "$100,000 - $149,999"     ~ 125000,
      q.demos.income == "$150,000 or more"        ~ 175000,
      TRUE                                        ~ NA_real_
    ),

    # Age: numeric midpoints
    q.demos.age = case_when(
      q.demos.age == "18 - 24 years" ~ 21,
      q.demos.age == "25 - 34 years" ~ 30,
      q.demos.age == "35 - 44 years" ~ 40,
      q.demos.age == "45 - 54 years" ~ 50,
      q.demos.age == "55 - 64 years" ~ 60,
      q.demos.age == "65 and older"  ~ 70,
      TRUE                           ~ NA_real_
    )
  )


## Convert all character and logical variables to factors
data <- data %>%
  mutate(across(where(is.character), as.factor),
         across(where(is.logical), as.factor))
```

```{r}
data
```


```{r, cache = TRUE}
## Handle Missing Data
imputation_pipeline <- gunion(list(
  # numeric features: regression tree imputation
  po("select", id = "sel_num", selector = selector_type("numeric")) %>>%
    po("imputelearner", id = "imp_num", learner = lrn("regr.rpart")),
  
  # factor / ordered features:classification tree imputation
  po("select", id = "sel_cat", selector = selector_type(c("factor","ordered"))) %>>%
    po("imputelearner", id = "imp_cat", learner = lrn("classif.rpart")),
  
  # everything else (IDs, dates, etc.) just passed through
  po("select", id = "sel_rest", selector = selector_invert(selector_type(c("numeric","factor","ordered"))))
  )) %>>%
  po("featureunion")

## Encode Variables
# impute variables
full_pipeline <- imputation_pipeline %>>%
  po("encode", method = "one-hot")
# defining the task
housing_tsk <- as_task_regr(data, target = "q.amazon.use.hh.size.num")
# train pipeline on the data
full_pipeline$train(housing_tsk)
# transform the data
encoded_data <- as.data.frame(full_pipeline$predict(housing_tsk)$data())

# Create learner
lrn_xgb <- as_learner(
  imputation_pipeline %>>%
    ## one-hot encode our categorical variables
    po("encode", method = "one-hot") %>>% 
    
    ## pass cleaned dataset into an XGBoost regression model
    lrn("regr.xgboost") 
)
```

Before modeling, we performed a few preprocessing steps to ensure the survey and purchase datasets were clean and suitable for regression. First, we removed several variables that were irrelevant to prediction. The variables related to the usage of personal information and the customers' survey identification number did not feel relevant to our goal of being able to predict the household size of a customer using their purchasing behavior. However, we will make another subset of data including the customers' survey identification number for a generative additive model to account for subject variance later on. From our EDA, we were able to decide that the shipping address state, order date, product-specific information, education level, gender, sexual orientation, order frequency, substance use, and personal health-related variables are not helpful for making our prediction. By removing these predictors, it also helps us prevent overfitting from occurring.


We still have the product category variable still to identify different products which we believe would also be more representative of different products. Since there are a lot of potential responses for this variable, we will limit the amount to the top 500 categories to make our modeling process less expensive. Additionally, we have decided the convert the q.amazon.use.howmany variable into a binary indicator called "Shared_Account" to indicate whether a customer's account is shared by others or is used be a single person. 

Since our dataset contains missing values, we decided to use rpart which can naturally handle missing values. In our pipeline, our numeric and categorical columns are separated, and then a regression and classification tree imputes the missing values respectively. Finally, we recombine all our features and have a clean dataset ready for modeling. 

```{r}
data
```
```{r}
#head(sort(table(data$category), decreasing = TRUE), 10)
```


## Candidate models / Model evaluation / Tuning
```{r}
# defining the task
housing_tsk <- as_task_regr(data, target = "q.amazon.use.hh.size.num")
```

```{r, cache=TRUE}
## 70/30 SPLIT

# set seed for reproducibility
set.seed(101) 

# randomly assign 70% of observations to train and 30% to test
split <- partition(housing_tsk, ratio = 0.70)

# define learner
lrn_lm <- as_learner(
  imputation_pipeline %>>%
    po("encode", method = "one-hot") %>>% ## one-hot encode our categorical variables
    lrn("regr.lm") ## pass cleaned dataset into a linear regression model
)

# train linear regression model on training data only
lrn_lm$train(task = housing_tsk, row_ids = split$train)
lrn_lm$model |> tidy()

# predict test data only
preds <- lrn_lm$predict(task = ames_tsk_small, row_ids = ames_split$test)

# performance on test data
preds$score(measures = msr("regr.mse"))
```


```{r, cache=TRUE}
## K FOLD CROSS VALIDATION

# resampling strategy
cv_5fold <- rsmp("cv", folds = 5) 

# defining the learner
lrn_lm <- as_learner(
  imputation_pipeline %>>%
    po("encode", method = "one-hot") %>>% ## one-hot encode our categorical variables
    lrn("regr.lm") ## pass cleaned dataset into a linear regression model
)

# set seed for reproducibility
set.seed(101) 
rr1 <- resample(task = housing_tsk, learner = lrn_lm, resampling = cv_5fold)
rr1$aggregate(measures = msrs(c("time_train", "time_predict", "time_both", "regr.mse")))
```




## Final Model
```{r}

```




